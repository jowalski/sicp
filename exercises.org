#+FILETAGS: @personal
#+LaTeX_HEADER: \newcommand{\mya}[2]{ ( A\, #1\, #2) }
#+LaTeX_HEADER: \usepackage{forest}
#+LaTeX_HEADER: \newcommand{\leaf}[3]{{(cc #1 #2)\\[-1ex]\scriptsize #3}}
* Exercises for the Structure and Interpretation of Computer Languages
:PROPERTIES:
:header-args: :results silent :noweb yes
:header-args: :noweb yes
:END:
** Chapter 1: Building Abstractions with Procedures
*** 1.2 Procedures and the Processes They Generate
#+LaTeX_HEADER: \newcommand{\mya}[2]{ ( A\, #1\, #2) }
**** 1.2.1 Linear Recursion and Iteration

*Linear recursion* - the length of the chain of deferred operations, as well as
the amount of information needed to keep track of it, grows linearly with \(n\).

*iterative process* - state can be summarized by a fixed number of state
variables, together with a fixed rule that describes how they should be updated.

[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::44][*Exercise 1.10*]]

The following procedure computes a mathematical function called Ackermann’s
function.

#+begin_src scheme :session
  (define (A x y)
    (cond ((= y 0) 0)
          ((= x 0)(* 2 y))
          ((= y 1) 2)
          (else (A (- x 1)
                   (A x (- y 1))))))
#+end_src

What are the values of the following expressions?

#+begin_src scheme
(A 1 10)
(A 2 4)
(A 3 3)
#+end_src

Consider the following procedures, where A is the procedure defined above:

#+begin_src scheme
(define (f n) (A 0 n))
(define (g n) (A 1 n))
(define (h n) (A 2 n))
(define (k n) (* 5 n n))
#+end_src

Give concise mathematical definitions for the functions computed by the
procedures f, g, and h for positive integer values of n. For example, (k n)
computes 5n 2.

Answer:

\[
\begin{align}
\mya{1}{x} &= \mya{0}{\mya{1}{(x - 1)}}   \\
           &= 2 \times \mya{1}{(x - 1)}   \\
\mya{1}{1} &= 2 \\
\mya{1}{x} &= 2^{x}
\end{align}
\]

Proof: \( \mya{1}{x} = 2 \times \mya{1}{(x - 1)} = 2 \times (2 ^{x - 1}) = 2
^{x}. \qedhere \)

\[
\begin{align}
\mya{2}{x} &= \mya{1}{\mya{2}{(x - 1)}} \\
           &= 2^{\mya{2}{(x - 1)}} \\
\mya{2}{1} &= 2 \\
\{\mya{2}{x}\} &= \{2, 2^2, 2^4, 2^8, \dots \} \\
           &= 2^{2^{x - 1}}
\end{align}
\]

Proof:
\[
\begin{align}
\mya{2}{x} &= 2^{\mya{2}{(x - 1)}} \\
           &= 2^{2^{2^{x - 2}}} \\
           &= 2^{2^{2^{x - 1} \times 2^{-1}}} \\
           &= 2^{(4^{x - 1})^{1/2}} \\
           &= 2^{2^{x - 1}}. \qedhere
\end{align}
\]
**** 1.2.2 Tree Recursion

*Example of tree recursion*: Counting Change
#+begin_src scheme
  (define (count-change amount)
    (cc amount 5))

  (define (cc amount kinds-of-coins)
    (cond ((= amount 0) 1)
          ((or (< amount 0) (= kinds-of-coins 0)) 0)
          (else (+ (cc amount
                       (- kinds-of-coins 1))
                   (cc (- amount
                          (first-denomination kinds-of-coins))
                       kinds-of-coins)))))

  (define (first-denomination kinds-of-coins)
    (cond ((= kinds-of-coins 1) 1)
          ((= kinds-of-coins 2) 5)
          ((= kinds-of-coins 3) 10)
          ((= kinds-of-coins 4) 25)
          ((= kinds-of-coins 5) 50)))
#+end_src

*Exercise 1.11*

A function f is defined by the rule that \(f(n) = n\) if \(n<3\) and \(f(n) = f(n - 1) + 2f(n - 2) + 3f(n - 3) \) if \(n \geq 3\). Write a procedure that computes \(f\) by means of a recursive process. Write a procedure that computes \(f\) by means of an iterative process.

=recursive=

a <- a + 2b + 3c
b <- a
c <- b

#+begin_src scheme
  (define (f n)
    (cond ((< n 3) n)
          (else (+ (f (- n 1))
                   (* 2 (f (- n 2)))
                   (* 3 (f (- n 3)))))))
#+end_src

=iterative=

#+begin_src scheme
  (define (fi n)
    (f-iter 2 1 0 n))

  (define (f-iter a b c count)
    (if (= count 0)
        c
        (f-iter (+ a (* 2 b) (* 3 c)) a b
                (- count 1))))
#+end_src

*Exercise 1.12*. The following pattern of numbers is called Pascal’s triangle. The numbers at the edge of the triangle are all 1, and each number inside the triangle is the sum of the two numbers above it. Write a procedure that computes elements of Pascal’s triangle by means of a recursive process.

#+begin_src scheme
  (define (pascal row column) ; the top is row 1,
    (if (or (= column 1)      ; the left side is col 1
            (= column row))
        1
        (+ (pascal (- row 1) column)
           (pascal (- row 1) (- column 1)))))
#+end_src

*Exercise 1.13*. Prove that \(Fib(n)\) is the closest integer to \(\phi^{n} / \sqrt{5}\), where \(\phi = (1 + \sqrt{5}) / 2\). Hint: Let \(\psi = (1 - \sqrt{5})/2\). Use induction and the definition of the Fibonacci numbers (see section 1.2.2) to prove that \(Fib(n) = ( \phi^{n} - \psi^{n})/ \sqrt{5}\).

_Proof_: \(Fib(1) = (\phi - \psi)/\sqrt{5} = \sqrt{5}/\sqrt{5} = 1\).

Assume \(Fib(n) = (\phi^{n}-\psi^{n})/\sqrt{5}\).
\[
\begin{align}
Fib(n + 1) &= Fib(n) + Fib(n-1) \\
           &= (\phi^{n}-\psi^{n}+\phi^{n-1}-\psi^{n-1})/\sqrt{5} \\
           &= ((\phi+1)\phi^{n-1} - (\psi+1) \psi^{n-1})/\sqrt{5} \\
           &= ((\frac{3+\sqrt{5}}{2})\phi^{n} - (\frac{3-\sqrt{5}}{2})\psi^{n})/\sqrt{5} \\
           &= (\phi^{2}\phi^{n-1} - \psi^{2}\psi^{n-1})/\sqrt{5} \\
           &= (\phi^{n+1} - \psi^{n+1})/\sqrt{5}
\end{align}
\]
**** 1.2.3 Orders of Growth
*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::48][Order of Growth]]*

\(R(n)\) has order of growth \(\Theta(f(n))\), written \(\R(n)=\Theta(f(n))\) (pronounced "theta of \(f(n)\)"), if there are positive constants \(k_{1}\) and \(k_{2}\) independent of \(n\) such that

\[ k_{1} f(n) \leq R(n) \leq k_{2} f(n) \]

for any sufficiently large value of \(n\).

*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::49][Exercise 1.14]]*. Draw the tree illustrating the process generated by the src_scheme{count-change} procedure of section 1.2.2 in making change for 11 cents. What are the orders of growth of the space and number of steps used by this process as the amount to be changed increases?

\[
\begin{forest} for tree={align=center}
[\leaf{11}{5}{4}
 [\leaf{11}{4}{4}
  [\leaf{11}{3}{4}
   [\leaf{11}{2}{3}
    [\leaf{11}{1}{1}
     [\leaf{11}{0}{0}]
     [\leaf{10}{1}{1}
      [\leaf{10}{0}{0}]
       [\dots
        [\leaf{0}{1}{1}]]]]
    [\leaf{6}{2}{2}
     [\leaf{6}{1}{1}
      [\dots [\leaf{0}{1}{1}]]]
     [\leaf{1}{2}{1}
      [\leaf{1}{1}{1}]
      [\leaf{-4}{2}{0}]]]]
   [\leaf{1}{3}{1}
    [\dots [\leaf{0}{1}{1}]]
    [\leaf{-9}{3}{0}]]]
  [\leaf{-14}{4}{0}]]
 [\leaf{-39}{5}{0}]]
\end{forest}
\]

An upper bound on the order of growth is \( (n + 1) \times (k + 1)\), where \(n\) is the total amount and \(k\) is the kinds of change.

Proof: We assert that all the possible argument pairs to the function that are called are integers \((i, j)\) with \(i = {0,\dots,n}\), \(j = {0,\dots,k}\), and each is called at most once. The first call is with \((n, k)\), thereafter each subsequent call either decreases the first argument or the second argument, but not both. So any given pair can be reached from a certain pair and prior operation: decrease \(i\) or decrease \(j\). ...

*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::49][Exercise 1.15]]*. The sine of an angle (specified in radians) can be computed by making use of the approximation \(sin x ~= x \) if \(x\) is sufficiently small, and the trigonometric identity
\[
\sin r = 3 \sin \frac{r}{3} - 4 \sin^{3} \frac{r}{3}
\]

to reduce the size of the argument of \(\sin\). (For purposes of this exercise an angle is considered "sufficiently small" if its magnitude is not greater than 0.1 radians.) These ideas are incorporated in the following procedures:

#+begin_src scheme :session sine
  (define (cube x) (* x x x))
  (define (p x) (- (* 3 x) (* 4 (cube x))))
  (define (sine angle)
    (if (not (> (abs angle) 0.1))
        angle
        (p (sine (/ angle 3.0)))))
#+end_src

#+RESULTS:

a. How many times is the procedure p applied when (sine 12.15) is evaluated?

This function displays the iteration and value.

#+begin_src scheme :results output :session sine
  (define (p x) (- (* 3 x) (* 4 (cube x))))
  (define (cube x) (* x x x))
  (define (sine-count angle iter)
    (define (disp-iter val)
      (display iter)
      (display " ")
      (display val)
      (display "\n")
      val)
    (if (not (> (abs angle) 0.1))
        angle
        (disp-iter (p (sine-count (/ angle 3.0) (+ iter 1))))))

  (sine-count 12.15 1)
#+end_src

#+RESULTS:
: "5 0.1495\n4 0.4351345505\n3 0.9758465331678772\n2 -0.7895631144708228\n1 -0.39980345741334\n"

b. What is the order of growth in space and number of steps (as a function of \(a\)) used by the process generated by the sine procedure when (sine a) is evaluated?

The order of growth in steps equivalent to how quickly \(a\) goes to 0 in the argument of the call to src_scheme{sine}, which the smallest integer \(n\) where \(\frac{a}{3^{n}} \leq 0.1\), or \(n \geq \log_{3} 10a\), so \(\Theta(\log_{3} a)\). The order of growth in space is the same.
**** 1.2.4 Exponentiation
The basic recursive procedure for exponentiation:

#+begin_src scheme
  (define (expt b n)
    (if (= n 0)
        1
        (* b (expt b (- n 1)))))
#+end_src

is \(\Theta(n)\) in # of steps and the same in space.

The iterative procedure:

#+begin_src scheme :session expt
  (define (expti b n)
    (expt-iter b n 0 1))

  (define (expt-iter b n iter product)
    (if (= iter n)
        product
        (expt-iter b n (+ iter 1) (* product b))))
#+end_src

is \(\Theta(n)\) in # of steps, but only \(\Theta(1)\) in space, since there are no deferred operations.

But even better, if we take advantage of successive squaring (\(b^{8}=b^{2}^{2}^{2}\)), we can get \(Theta(\log n)\) in steps and space.

#+NAME: fast_exp
#+begin_src scheme :session expt
  (define (square a) (* a a))

  (define (even? n)
    (= (remainder n 2) 0))

  (define (fast-exp b n)
    (cond ((= n 0) 1)
          ((even? n) (square (fast-exp b (/ n 2))))
          (else (* b (fast-exp b (- n 1))))))
#+end_src

The argument to, at worst every other call of fast-exp, is halved.

*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::51][Exercise 1.16]]*

Design a procedure that evolves an iterative exponentiation process that uses successive squaring and uses a logarithmic number of steps, as does fast-expt. (Hint: Using the observation that \((b^{n/2})^{2} = (b^{2})^{n/2}\) , keep, along with the exponent \(n\) and the base \(b\), an additional state variable \(a\), and define the state transformation in such a way that the product \(a b^{n}\) is unchanged from state to state. At the beginning of the process \(a\) is taken to be 1, and the answer is given by the value of \(a\) at the end of the process. In general, the technique of defining an invariant quantity that remains unchanged from state to state is a powerful way to think about the design of iterative algorithms.)

#+begin_src scheme
  (define (square a) (* a a))

  (define (fast-expti b n)
    (fast-expt-iter n b 1))

  (define (fast-expt-iter n base a)
    (cond ((= n 0) 1)
          ((= n 1) (* base a))
          ((even? n) (fast-expt-iter (/ n 2) (square base) a))
          (else (fast-expt-iter (- n 1) base (* base a)))))
#+end_src

The pseudocode for this is:

#+begin_src
base = b
a = 1

if (n == 1) return 1

while (n > 1) {
  if (even? n) {
    base *= base
    n /= 2
  } else {
    a *= base
    n--
  }
}
base * a
#+end_src

*Exercise 1.17*. The exponentiation algorithms in this section are based on performing exponentiation by means of repeated multiplication. In a similar way, one can perform integer multiplication by means of repeated addition. The following multiplication procedure (in which it is assumed that our language can only add, not multiply) is analogous to the src_scheme{expt} procedure:

#+begin_src scheme
  (define (* a b)
    (if (= b 0)
        0
        (+ a (* a (- b 1)))))

#+end_src

This algorithm takes a number of steps that is linear in =b=. Now suppose we include, together with addition, operations =double=, which doubles an integer, and =halve=, which divides an (even) integer by 2. Using these, design a multiplication procedure analogous to =fast-expt= that uses a logarithmic number of steps.

#+begin_src scheme
  (define (double a) (+ a a))
  (define (halve a) (/ a 2))

  (define (fast-mult b n)
    (cond ((= n 0) 0)
          ((even? n) (double (fast-mult b (halve n))))
          (else (+ b (fast-mult b (- n 1))))))
#+end_src

*Exercise 1.18*. Using the results of exercises 1.16 and 1.17, devise a procedure that generates an iterative process for multiplying two integers in terms of adding, doubling, and halving and uses a logarithmic number of steps.

#+begin_src scheme
  (define (square a) (* a a))

  (define (fast-multi b n)
    (fast-mult-iter n b 0))

  (define (fast-mult-iter n base a)
    (cond ((= n 0) 0)
          ((= n 1) (+ base a))
          ((even? n) (fast-mult-iter (halve n) (double base) a))
          (else (fast-mult-iter (- n 1) base (+ base a)))))
#+end_src

*Exercise 1.19*. There is a clever algorithm for computing the Fibonacci numbers in a logarithmic number of steps. Recall the transformation of the state variables a and b in the fib-iter process of section 1.2.2: \(a \leftarrow a + b\) and \(b \leftarrow a\). Call this transformation \(T\), and observe that applying \(T\) over and over again \(n\) times, starting with 1 and 0, produces the pair \(Fib(n + 1)\) and \(Fib(n)\). In other words, the Fibonacci numbers are produced by applying \(T^{n}\) , the nth power of the transformation \(T\), starting with the pair \((1,0)\). Now consider \(T\) to be the special case of \(p = 0\) and \(q = 1\) in a family of transformations \(T_{pq}\) , where \(T_{pq}\) transforms the pair \((a,b)\) according to \(a \leftarrow bq + aq + ap\) and \(b \leftarrow bp + aq\). Show that if we apply such a transformation \(T_{pq}\) twice, the effect is the same as using a single transformation \(T_{p’q'}\) of the same form, and compute p’ and q’ in terms of p and q. This gives us an explicit way to square these transformations, and thus we can compute T n using successive squaring, as in the fast-expt procedure. Put this all together to complete the following procedure, which runs in a logarithmic number of steps:

Answer: Start by rewriting \((T_{pq})^{2}\):

\[
\begin{align}
a & \leftarrow b_{1}q + a_{1}q + a_{1}p \\
  & = (bp + aq)q + (bq + aq + ap)q + (bq + aq + ap)p \\
  & = ap^{2} + 2(b + a)pq + (2a + b)q^{2} \\
  & = (b + a)q' + ap'
\end{align}
\]

\[
\begin{align}
b & \leftarrow b_{1}p + a_{1}q \\
  & = (bp + aq)p + (bq + aq + ap)q \\
  & = bp^{2} + 2apq + (a + b)q^{2} \\
  & = bp' + aq'
\end{align}
\]

These are solved with:

\[
\begin{align}
q' & = 2pq + q^2 \\
p' & = p^{2} + q^2
\end{align}
\]

#+begin_src scheme
  (define (fib n)
    (fib-iter 1 0 0 1 n))

  (define (fib-iter a b p q count)
    (cond ((= count 0) b)
          ((even? count)
           (fib-iter a b
                     (+ (square p) (square q))  ; compute p’
                     (+ (* 2 p q) (square q))   ; compute q’
                     (/ count 2)))
          (else (fib-iter (+ (* b q) (* a q) (* a p))
                          (+ (* b p) (* a q))
                          p q (- count 1)))))
#+end_src
**** 1.2.5 Greatest Common Divisors
Review,*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::53][Euclid's method]]* for computing GCD:

#+NAME: gcd
#+begin_src scheme
  (define (gcd a b)
    (if (= b 0)
        a
        (gcd b (remainder a b))))
#+end_src

Interesting relationship to Fibonacci numbers.

*Lame's Theorem*: if Euclid's Algorithm takes \(k\) steps to compute the GCD of some pair, then the smaller number in the pair must be greater than or equal to the \(k\)th Fibonacci number.

Exercise 1.20. The process that a procedure generates is of course dependent on the rules used by the interpreter. As an example, consider the iterative gcd procedure given above. Suppose we were to interpret this procedure using normal-order evaluation, as discussed in section 1.1.5. (The normal-order-evaluation rule for if is described in exercise 1.5.) Using the substitution method (for normal order), illustrate the process generated in evaluating (gcd 206 40) and indicate the remainder operations that are actually performed. How many remainder operations are actually performed in the normal-order evaluation of (gcd 206 40)? In the applicative-order evaluation?

Normal order:
#+begin_src scheme
  (gcd 206 40)
  (if (= 40 0) 206 (gcd 40 (remainder 206 40)))
  (gcd 40 (remainder 206 40))
  (if (= (remainder 206 40) 0) 40 (gcd (remainder 206 40) (remainder 40 (remainder 206 40))))
  ;; remainder performed here => 6
  (gcd (remainder 206 40) (remainder 40 (remainder 206 40)))
  (if (= (remainder 40 (remainder 206 40)) 0) (remainder 206 40) (gcd (remainder 40 (remainder 206 40)) (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))))
  ;; 2 remainders performed here => 4
  (gcd (remainder 40 (remainder 206 40)) (remainder (remainder 206 40) (remainder 40 (remainder 206 40))))
  (if ...)
  ;; 3 remainders performed here? => 2
  (gcd ...)
  (if ...)
  ;; 4 remainders performed here => 0
  (remainder ...)
  ;; 3 remainders performed to get answer
  2
#+end_src

\(1 + 2 + 3 + 4 + 3 = 13\) remainder calculations?

Applicative order:
#+begin_src scheme
  (gcd 206 40)
  (gcd 40 (remainder 206 40))
  (gcd 40 6)
  (gcd 6 (remainder 40 6))
  (gcd 6 4)
  (gcd 4 (remainder 6 4))
  (gcd 4 2)
  (gcd 2 (remainder 4 2))
  (gcd 2 0)
  2
#+end_src

4 remainder calculations
**** 1.2.6 Example: Testing for Primality
*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::54][Fermat's Little Theorem]]*: If n is a prime number and a is any positive integer less than n, then a raised to the nth power is congruent to a modulo n.

*congruent modulo n* means they both have the same remainder when divided by n.

*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::55][Exercise 1.21]]*. Use the smallest-divisor procedure to find the smallest divisor of each of the following numbers: 199, 1999, 19999.

#+NAME: fast_prime
#+begin_src scheme
  (define (square a) (* a a))

  (define (expmod base exp m)
    (cond ((= exp 0) 1)
          ((even? exp)
           (remainder (square (expmod base (/ exp 2) m))
                      m))
          (else
           (remainder (* base (expmod base (- exp 1) m))
                      m))))

  (define (fermat-test n)
    (define (try-it a)
      (= (expmod a n n) a))
    (try-it (+ 1 (random (- n 1)))))

  (define (fast-prime? n times)
    (cond ((= times 0) #t)
          ((fermat-test n) (fast-prime? n (- times 1)))
          (else #f)))
#+end_src

#+NAME: smallest_divisor
#+begin_src scheme
  (define (square a) (* a a))

  (define (smallest-divisor n)
    (find-divisor n 2))

  (define (find-divisor n test-divisor)
    (cond ((> (square test-divisor) n) n)
          ((divides? test-divisor n) test-divisor)
          (else (find-divisor n (+ test-divisor 1)))))

  (define (divides? a b)
    (= (remainder b a) 0))
#+end_src

#+begin_src scheme :results value replace
  <<smallest_divisor>>
  (map smallest-divisor (list 199 1999 19999))
#+end_src

#+RESULTS:
: (199 1999 7)

*Exercise 1.22*. Most Lisp implementations include a primitive called runtime that returns an integer that specifies the amount of time the system has been running (measured, for example, in microseconds). The following timed-prime-test procedure, when called with an integer n, prints n and checks to see if n is prime. If n is prime, the procedure prints three asterisks followed by the amount of time used in performing the test.

#+NAME: timed_prime
#+begin_src scheme
  ;; need this in guile
  (define runtime get-internal-run-time)

  (define (timed-prime-test n)
    (start-prime-test n (runtime)))

  (define (start-prime-test n start-time)
    (if (prime? n)
        (report-prime (- (runtime) start-time) n)))

  (define (report-prime elapsed-time n)
    (display n)
    (display " *** ")
    (display elapsed-time)
    (newline))
#+end_src

Using this procedure, write a procedure search-for-primes that checks the primality of consecutive odd integers in a specified range. Use your procedure to find the three smallest primes larger than 1000; larger than 10,000; larger than 100,000; larger than 1,000,000. Note the time needed to test each prime. Since the testing algorithm has order of growth of \(\Theta(\sqrt{n})\), you should expect that testing for primes around 10,000 should take about \(\sqrt{10}\) times as long as testing for primes around 1000. Do your timing data bear this out? How well do the data for 100,000 and 1,000,000 support the n prediction? Is your result compatible with the notion that programs on your machine run in time proportional to the number of steps required for the computation?

#+NAME: test_primes
#+begin_src scheme
  (define (test-and-continue n m)
    (timed-prime-test n)
    (search-for-primes (+ n 2) m))

  (define (search-for-primes n m)
    (if (< n m)
        (test-and-continue n m)))

  (search-for-primes 1001 1020)
  (search-for-primes 10001 10038)
  (search-for-primes 100001 100044)
  (search-for-primes 1000001 1000038)
#+end_src

#+NAME: search_for_primes
#+begin_src scheme :results output replace
  <<smallest_divisor>>
  <<timed_prime>>

  (define (prime? n)
    (= n (smallest-divisor n)))

  <<test_primes>>
#+end_src

#+RESULTS: search_for_primes
: "1009 *** 5226\n1013 *** 5231\n1019 *** 5018\n10007 *** 15190\n10009 *** 15567\n10037 *** 15388\n100003 *** 47888\n100019 *** 46513\n100043 *** 47711\n1000003 *** 155896\n1000033 *** 146287\n1000037 *** 149025\n"

Yes, the difference in timing for testing each prime is roughly equal to \(\sqrt{10}\).

*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::56][Exercise 1.23]]* The =smallest-divisor= procedure shown at the start of this section does lots of needless testing: After it checks to see if the number is divisible by 2 there is no point in checking to see if it is divisible by any larger even numbers. This suggests that the values used for =test-divisor= should not be 2, 3, 4, 5, 6, ..., but rather 2, 3, 5, 7, 9, .... To implement this change, define a procedure =next= that returns 3 if its input is equal to 2 and otherwise returns its input plus 2. Modify the =smallest-divisor= procedure to use =(next test-divisor)= instead of =(+ test-divisor 1)=. With timed-prime-test incorporating this modified version of smallest-divisor, run the test for each of the 12 primes found in exercise 1.22. Since this modification halves the number of test steps, you should expect it to run about twice as fast. Is this expectation confirmed? If not, what is the observed ratio of the speeds of the two algorithms, and how do you explain the fact that it is different from 2?

#+begin_src scheme :results output raw replace
  <<smallest_divisor>>
  <<timed_prime>>

  (define (smallest-divisor-fast n)
    (find-divisor-fast n 2))

  (define (next n)
    (if (= n 2) 3 (+ n 2)))

  (define (find-divisor-fast n test-divisor)
    (cond ((> (square test-divisor) n) n)
          ((divides? test-divisor n) test-divisor)
          (else (find-divisor-fast n (next test-divisor)))))

  (define (prime? n)
    (= n (smallest-divisor-fast n)))

  <<test_primes>>
#+end_src

#+RESULTS:
"1009 *** 3692\n1013 *** 3662\n1019 *** 3565\n10007 *** 9692\n10009 *** 9595\n10037 *** 9700\n100003 *** 29441\n100019 *** 29209\n100043 *** 33358\n1000003 *** 90914\n1000033 *** 90855\n1000037 *** 94327\n"

No. The ratio in times is closer to 1.5. This is because =find-divisor= is \(\Theta(\sqrt{n})\) itself, due to checking only for divisors up to \(\sqrt{n}\).

*Exercise 1.24*. Modify the =timed-prime-test= procedure of exercise 1.22 to use =fast-prime?= (the Fermat method), and test each of the 12 primes you found in that exercise. Since the Fermat test has \(\Theta(\log n)\) growth, how would you expect the time to test primes near 1,000,000 to compare with the time needed to test primes near 1000? Do your data bear this out? Can you explain any discrepancy you find?

You would expect the fractional difference in time to be \(\frac{\log{10^{6}}}{\log{10^{3}}} = 2\).

#+begin_src scheme :results output raw replace
  <<timed_prime>>
  <<fast_prime>>

  (define prime? (lambda (x) (fast-prime? x 10)))

  <<test_primes>>
#+end_src

#+RESULTS:
"1009 *** 43200\n1013 *** 44989\n1019 *** 46135\n10007 *** 56087\n10009 *** 58798\n10037 *** 58003\n100003 *** 65648\n100019 *** 67945\n100043 *** 67947\n1000003 *** 75438\n1000033 *** 75835\n1000037 *** 78192\n"

That is *roughly* the case, though it appears to be somewhat less than that. It could because algorithm is probabilistic, and the chance of a match for a prime as a function of n is affecting things. Also, the call to =random= may also have an effect.

*Exercise 1.25*. Alyssa P. Hacker complains that we went to a lot of extra work in writing =expmod=. After all, she says, since we already know how to compute exponentials, we could have simply written

#+NAME: expmod_simple
#+begin_src scheme
  (define (expmod-simple base exp m)
    (remainder (fast-exp base exp) m))
#+end_src

Is she correct? Would this procedure serve as well for our fast prime tester? Explain.

First off, why is it always a hypothetical female that seems to be mistaken in these examples?

This would have us creating on average exponents of size \((n/2)^{n}\), which will take up exponentially increasing amounts of space in addition to whatever additional time cost there is to =remainder=. In addition, =remainder= probably has some cost for large values.

#+begin_src scheme :results output raw replace
  <<fast_exp>>
  <<expmod_simple>>

  (define runtime get-internal-run-time)

  (define (timed-expmod-test n)
    (start-expmod-test n (runtime)))

  (define (start-expmod-test n start-time)
    (expmod-simple (+ 1 (random (- n 1))) n n)
    (report-expmod (- (runtime) start-time) n))

  (define (report-expmod elapsed-time n)
    (display n)
    (display " *** ")
    (display elapsed-time)
    (newline))

  (map timed-expmod-test (list 101 1001 10001 100001))
#+end_src

#+RESULTS:
"101 *** 34449\n1001 *** 24503\n10001 *** 299949\n100001 *** 7257138\n"

This test seems to confirm the time cost increases exponentially.

*Exercise 1.26*. Louis Reasoner is having great difficulty doing exercise 1.24. His fast-prime? test seems to run more slowly than his prime? test. Louis calls his friend Eva Lu Ator over to help. When they examine Louis’s code, they find that he has rewritten the expmod procedure to use an explicit multiplication, rather than calling square:

#+begin_src scheme
  (define (expmod base exp m)
    (cond ((= exp 0) 1)
          ((even? exp)
           (remainder (* (expmod base (/ exp 2) m)
                         (expmod base (/ exp 2) m))
                      m))
          (else
           (remainder (* base (expmod base (- exp 1) m))
                      m))))
#+end_src

"I don’t see what difference that could make," says Louis. "I do." says Eva. "By writing the procedure like that, you have transformed the \(\Theta(\log{n})\) process into a \(\Theta(n)\) process." Explain.

For each even exponent calculation, =expmod= will be called twice instead of once. Given that expmod is \(\Theta(\log{n})\), this implies \(2^{\log{n}} = n\) calculations.

*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::57][Exercise 1.27]]*. Demonstrate that the Carmichael numbers listed in footnote 47 really do fool the Fermat test. That is, write a procedure that takes an integer n and tests whether \(a^{n}\) is congruent to \(a\) modulo \(n\) for every \(a<n\), and try your procedure on the given Carmichael numbers.

#+begin_src scheme :results value replace
  <<fast_prime>>
  <<smallest_divisor>>
  (define (test-congruent a n)
    (= (expmod a n n) (remainder a n)))

  (define (fool-fermat? n)
    (fool-fermat-iter 2 n))

  (define (fool-fermat-iter a n)
    (or (>= a n)
        (and (test-congruent a n) (fool-fermat-iter (+ a 1) n))))

  (map fool-fermat? (list 561 1105 1729 2465 2821 6601))
#+end_src

#+RESULTS:
: (#t #t #t #t #t #t)

And just to confirm they aren't primes.

#+begin_src scheme :results value replace
  <<smallest_divisor>>
  (define (prime? n)
    (= n (smallest-divisor n)))
  (map prime? (list 561 1105 1729 2465 2821 6601))
#+end_src

#+RESULTS:
: (#f #f #f #f #f #f)

*Exercise 1.28* TODO
*** 1.3 Formulating Abstractions with Higher-Order Procedures
*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::60][Higher-order procedures]]* are procedures that manipulate procedures. Often the same programming pattern will be used with different procedures, it would be limiting not to be able to express these patterns in the language.

**** 1.3.1 Procedures as Arguments
We can write an abstract summing procedure, where =term= and =next= are procedures themselves that evaluate and increment the iteration respectively.

#+NAME: sum
#+begin_src scheme
  (define (sum term a next b)
    (if (> a b)
        0
        (+ (term a)
           (sum term (next a) next b))))
#+end_src

#+NAME: integral
#+begin_src scheme
  (define (integral f a b dx)
    (define (add-dx x) (+ x dx))
    (* (sum f (+ a (/ dx 2.0)) add-dx b)
       dx))
#+end_src

*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::63][Exercise 1.29]]*. Simpson’s Rule is a more accurate method of numerical integration than the method illustrated above. Using Simpson’s Rule, the integral of a function f between a and b is approximated as where \(h = (b - a)/n\), for some even integer n, and \(y_{k} = f(a + kh)\). (Increasing n increases the accuracy of the approximation.) Define a procedure that takes as arguments f, a, b, and n and returns the value of the integral, computed using Simpson’s Rule. Use your procedure to integrate cube between 0 and 1 (with n = 100 and n = 1000), and compare the results to those of the integral procedure shown above.

#+NAME: simpsons
#+begin_src scheme
  ;; the coefficients of each term
  (define (simp-coef k n)
    (cond ((or (= k 0) (= k n)) 1)
          ((odd? k) 4)
          (else 2)))

  ;; this is a "generic" simpsons, taking arbitrary
  ;; coefficients and constant
  (define (simp-sum-generic f n a b coef const)
    (define (simpterm i)
      (* (coef i n) (f (+ a (* (/ i n) (- b a))))))
    (define (simpnext i) (+ i 1))
    (* const (sum simpterm 0 simpnext n)))

  (define (simpsons f n a b)
    (simp-sum-generic f n a b simp-coef (/ (- b a) (* n 3))))
#+end_src

#+NAME: simpsons-approx
#+begin_src scheme :results value replace
  <<sum>>
  <<integral>>
  <<simpsons>>

  (define (cube x) (* x x x))

  (define (approx-compare n)
    (list (simpsons cube n 0 1)
        (integral cube 0 1 (/ 1 n))))

  (map approx-compare (list 100 1000))
#+end_src

#+RESULTS: simpsons-approx
: ((1/4 0.24998750000000042) (1/4 0.249999875000001))

*Exercise 1.30*. The sum procedure above generates a linear recursion. The procedure can be rewritten so that the sum is performed iteratively. Show how to do this by filling in the missing expressions in the following definition:

#+begin_src scheme sum
  ;; (define (sum term a next b)
  ;;   (define (iter a result)
  ;;     (if <??>
  ;;         <??>
  ;;         (iter <??> <??>)))
  ;;   (iter <??> <??>))

  (define (sumi term a next b)
    (define (iter i result)
      (if (> i b)
          result
          (iter (next i) (+ result (term i)))))
    (iter a 0))
#+end_src

*Exercise 1.31*.
a. The =sum= procedure is only the simplest of a vast number of similar abstractions that can be captured as higher-order procedures. Write an analogous procedure called product that returns the product of the values of a function at points over a given range. Show how to define factorial in terms of product. Also use product to compute approximations to \(\pi\) using the formula

\[
\frac{\pi}{4} = \frac{2 \cdot 4 \cdot 4 \cdot 6 \cdot 6 \cdot 8 \dots}{3 \cdot 3 \cdot 5 \cdot 5 \cdot 7 \cdot 7 \dots}
\]

#+NAME: product
#+begin_src scheme
  (define (prodi term a next b)
    (define (iter i result)
      (if (> i b)
          result
          (iter (next i) (* result (term i)))))
    (iter a 1))

  (define (prodr term a next b)
    (if (> a b)
        1
        (* (term a)
           (prodr term (next a) next b))))

  (define (pi-approx n)
    (define (iter i) (+ i 1))
    (define (imod2 i) (+ i (remainder i 2)))
    (define (term i) (/ (imod2 (+ i 1)) (+ 1 (imod2 i))))
    (* 4 (prodi term 1 iter n)))
#+end_src

b. If your product procedure generates a recursive process, write one that generates an iterative process. If it generates an iterative process, write one that generates a recursive process.

*Exercise 1.32*. a. Show that sum and product (exercise 1.31) are both special cases of a still more general notion called accumulate that combines a collection of terms, using some general accumulation function:

#+begin_src scheme
  (accumulate combiner null-value term a next b)
#+end_src

=accumulate= takes as arguments the same term and range specifications as =sum= and =product=, together with a =combiner= procedure (of two arguments) that specifies how the current term is to be combined with the accumulation of the preceding terms and a =null-value= that specifies what base value to use when the terms run out. Write =accumulate= and show how =sum= and =product= can both be defined as simple calls to =accumulate=.

#+NAME: accumulate
#+begin_src scheme :results value replace
  (define (accumulatei combiner null-value term a next b)
    (define (iter i result)
      (if (= i (next b))
          result
          (iter (next i) (combiner result (term i)))))
    (iter a null-value))

  (define (accumulater combiner null-value term a next b)
    (if (= a (next b))
        null-value
        (combiner a (accumulater combiner null-value
                     term (next a) next b))))

  (define (suma term a next b)
    (accumulatei + 0 term a next b))

  (define (proda term a next b)
    (accumulatei * 1 term a next b))

  <<sum>>
  <<product>>

  (define (accum-compare f f-accum term a next b)
    (list (f term a next b) (f-accum term a next b)))

  (define (identity x) x)
  (define (inc x) (+ x 1))

  (list (accum-compare sum suma identity 10 inc 20)
        (accum-compare prodi proda identity 10 inc 20)
        (accumulater + 0 identity 10 inc 20)
        (accumulater * 1 identity 10 inc 20))
#+end_src

#+RESULTS: accumulate
: ((165 165) (6704425728000 6704425728000) 165 6704425728000)

b. If your accumulate procedure generates a recursive process, write one that generates an iterative process. If it generates an iterative process, write one that generates a recursive process.

(see =accumulater= above, and the final test)

*Exercise 1.33*. You can obtain an even more general version of accumulate (exercise 1.32) by introducing the notion of a filter on the terms to be combined. That is, combine only those terms derived from values in the range that satisfy a specified condition. The resulting =filtered-accumulate= abstraction takes the same arguments as =accumulate=, together with an additional predicate of one argument that specifies the filter. Write =filtered-accumulate= as a procedure. Show how to express the following using filtered-accumulate:

#+NAME: filtered_accumulate
#+begin_src scheme
  (define (filtered-accumulate combiner filter null-value term a next b)
    (define (iter i result)
      (if (= i (next b))
          result
          (iter (next i)
                (combiner result (if (filter i) (term i) null-value)))))
    (iter a null-value))
#+end_src

a. the sum of the squares of the prime numbers in the interval a to b (assuming that you have a =prime?= predicate already written)

#+begin_src scheme
  <<filtered_accumulate>>
  <<smallest_divisor>>

  (define (square x) (* x x))

  (define (prime? n)
    (= n (smallest-divisor n)))

  (define (inc x) (+ x 1))

  (define (sum-sq-primes a b)
     (filtered-accumulate + prime? 0 square a inc b))
#+end_src

b. the product of all the positive integers less than n that are relatively prime to n (i.e., all positive integers \(i < n\) such that \(GCD(i,n) = 1\)).

#+begin_src scheme :results value replace
  <<filtered_accumulate>>
  <<gcd>>
  (define (rel-prime? a b) (= (gcd a b) 1))
  (define (identity x) x)
  (define (inc x) (+ x 1))
  (define (prod-rel-prime n)
     (define (rel-prime-n? x) (rel-prime? x n))
     (filtered-accumulate * rel-prime-n? 1 identity 1 inc n))

  (map prod-rel-prime (list 1 2 3 4 5 6 7))
#+end_src

#+RESULTS:
: (1 1 2 3 24 5 720)

**** 1.3.2 Constructing Procedures Using =Lambda=
[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::64][=lambda=]] can be read as "the procedure of an argument(s) x, ... that ..."

[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::66][=let=]] is a special form of =lambda=.

#+begin_src scheme
  (let ((<var-1 > <exp-1 >)
        (<var-2 > <exp-2 >)
        ...
        (<var-n > <exp-n >))
    <body>)

  ((lambda (<var-1 > ...<var-n >)
     <body>)
   <exp-1>
   ...
   <exp-n>)
#+end_src

*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::67][Exercise 1.34]]*. Suppose we define the procedure

#+begin_src scheme
(define (f g)
  (g 2))
#+end_src

Then we have

#+begin_src scheme
(f square)
4
(f (lambda (z) (* z (+ z 1))))
6
#+end_src

What happens if we (perversely) ask the interpreter to evaluate the combination src_scheme{(f f)}? Explain.

We can think of g as a lambda.

#+begin_src scheme
  (f (lambda (h) (h 2)))
  ((lambda (h) (h 2)) 2)
  (2 2)
  ; error?, can't apply 2

  (f f)
  (f 2)
  (2 2)
#+end_src
**** 1.3.3 Procedures as General Methods
A *[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::69][fixed point]]* satisfies \(f(x) = x\). It's common to find fixed points by starting with a guess and repeatedly applying \(f\), so \(f(a), f(f(a)), f(f(f(a))), \dots\).

#+NAME: fixed_point
#+begin_src scheme
  (define tolerance 0.00001)
  (define (fixed-point f first-guess)
    (define (close-enough? v1 v2)
      (< (abs (- v1 v2)) tolerance))
    (define (try guess)
      (let ((next (f guess)))
        (if (close-enough? guess next)
            next
            (try next))))
    (try first-guess))
#+end_src

Observation: finding a square root of \(x\) (the \(y\) such that \(y^{2}=x\)) is just finding a fixed point of \(f(y) = x/y\). If we used the standard method, we'd get \(y_{1}, x / y_{1}, x/(x/y_{1}) = y_{1}, \dots \), which just oscillates between \(x\) and our first and second guesses.

One way to deal with this is to make better guesses, and since the answer is always between the guess \(y\) and \(y/x\), use the average. So instead of the second guess being \(x / y_{1}\), it is \(\frac{y_{1} + x/y_{1}}{2}\).

This is a fixed point of \(f(y) = (1/2)(y + x/y)\), which is another way of writing \(y=f(y)=x/y\) (just add \(y\) to each side, \(2y=y + x/y\)).

This is called *average damping*.

*Exercise 1.35*. Show that the golden ratio (section 1.2.2) is a fixed point of the transformation \(x + 1/x\), and use this fact to compute by means of the fixed-point procedure.

The golden ratio satisfies: \(\phi^{2} = \phi + 1\), which can be rewritten \(\phi = 1 + \frac{1}{\phi}\).

#+NAME: golden_ratio
#+begin_src scheme :results replace
<<fixed_point>>
(fixed-point (lambda (x) (+ 1 (/ 1 x))) 1.0)
#+end_src

#+RESULTS: golden_ratio
: 1.6180327868852458

*[[pdfview:/home/jowalski/usbcrypt/sicp.pdf::71][Exercise 1.36]]*. Modify fixed-point so that it prints the sequence of approximations it generates, using the newline and display primitives shown in exercise 1.22. Then find a solution to \(x^{x} = 1000\) by finding a fixed point of \(x \rightarrow \log(1000)/\log(x)\). (Use Scheme’s primitive log procedure, which computes natural logarithms.) Compare the number of steps this takes with and without average damping. (Note that you cannot start fixed-point with a guess of 1, as this would cause division by log(1) = 0.)

#+NAME: fixed_point_print
#+begin_src scheme
  (define (fixed-point-print f first-guess)
    (define (close-enough? v1 v2)
      (< (abs (- v1 v2)) tolerance))
    (define (try guess)
      (display guess)
      (newline)
      (let ((next (f guess)))
        (if (close-enough? guess next)
            next
            (try next))))
    (try first-guess))
#+end_src

#+begin_src scheme
  ()
#+end_src
